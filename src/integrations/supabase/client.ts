// This file is automatically generated. Do not edit it directly.
import { createClient } from '@supabase/supabase-js';
import type { Database } from './types';

const SUPABASE_URL = import.meta.env.VITE_SUPABASE_URL;
const SUPABASE_PUBLISHABLE_KEY = import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY;

// Import the supabase client like this:
// import { supabase } from "@/integrations/supabase/client";

export const supabase = createClient<Database>(SUPABASE_URL, SUPABASE_PUBLISHABLE_KEY, {
  auth: {
    storage: localStorage,
    persistSession: true,
    autoRefreshToken: true,
  }
});

// Helper function for Prompt Expert to update agent prompts
export async function updateAgentPrompt(agentSlugOrId: string, newSystemPrompt: string, updatedBy?: string) {
  return supabase.functions.invoke('update-agent-prompt', {
    body: { 
      agentSlugOrId, 
      newSystemPrompt,
      updatedBy 
    }
  });
}

// Helper to update filter agent prompt
export async function updateFilterPrompt(
  newPromptContent: string, 
  filterVersion?: string,
  notes?: string
) {
  const { data: userData } = await supabase.auth.getUser();
  return supabase.functions.invoke('update-filter-prompt', {
    body: { 
      newPromptContent,
      filterVersion,
      notes,
      updatedBy: userData.user?.id,
    }
  });
}

// Helper to force knowledge alignment analysis
export async function forceAlignmentAnalysis(agentId: string) {
  // Extract requirements
  await supabase.functions.invoke('extract-task-requirements', {
    body: { agentId }
  });
  
  // Analyze alignment with force flag
  return supabase.functions.invoke('analyze-knowledge-alignment', {
    body: { 
      agentId,
      forceReanalysis: true
    }
  });
}

// Force trigger embedding generation for all pipelines
// Call from browser console: (await import('@/integrations/supabase/client')).triggerAllEmbeddings()
export async function triggerAllEmbeddings() {
  console.log('üöÄ Triggering embedding generation for all pipelines...\n');

  const pipelines = [
    'pipeline-a-generate-embeddings',
    'pipeline-a-hybrid-generate-embeddings',
    'pipeline-b-generate-embeddings',
    'pipeline-c-generate-embeddings',
  ];

  for (const fn of pipelines) {
    console.log(`Invoking ${fn}...`);
    try {
      const { data, error } = await supabase.functions.invoke(fn, { body: {} });
      if (error) {
        console.error(`  ‚ùå Error: ${error.message}`);
      } else {
        console.log(`  ‚úÖ Result:`, data);
      }
    } catch (e) {
      console.error(`  ‚ùå Exception:`, e);
    }
  }

  console.log('\n‚úÖ All embedding functions triggered.');
}

// Debug function to diagnose stuck documents in queue
// Call from browser console: (await import('@/integrations/supabase/client')).diagnoseStuckDocuments()
export async function diagnoseStuckDocuments() {
  console.log('üîç Diagnosing stuck documents...\n');

  // Check all pipelines for chunked documents
  const pipelines = [
    { name: 'Pipeline A', table: 'pipeline_a_documents', chunksTable: 'pipeline_a_chunks_raw' },
    { name: 'Pipeline A-Hybrid', table: 'pipeline_a_hybrid_documents', chunksTable: 'pipeline_a_hybrid_chunks_raw' },
    { name: 'Pipeline B', table: 'pipeline_b_documents', chunksTable: 'pipeline_b_chunks_raw' },
    { name: 'Pipeline C', table: 'pipeline_c_documents', chunksTable: 'pipeline_c_chunks_raw' },
  ];

  for (const pipeline of pipelines) {
    const { data: chunkedDocs } = await supabase
      .from(pipeline.table)
      .select('id, file_name, status, created_at, updated_at')
      .eq('status', 'chunked');

    if (chunkedDocs && chunkedDocs.length > 0) {
      console.log(`\nüìÅ ${pipeline.name}: ${chunkedDocs.length} document(s) in 'chunked' status`);

      for (const doc of chunkedDocs) {
        // Get chunk stats for this document
        const { count: totalChunks } = await supabase
          .from(pipeline.chunksTable)
          .select('id', { count: 'exact', head: true })
          .eq('document_id', doc.id);

        const { count: pendingChunks } = await supabase
          .from(pipeline.chunksTable)
          .select('id', { count: 'exact', head: true })
          .eq('document_id', doc.id)
          .eq('embedding_status', 'pending');

        const { count: readyChunks } = await supabase
          .from(pipeline.chunksTable)
          .select('id', { count: 'exact', head: true })
          .eq('document_id', doc.id)
          .eq('embedding_status', 'ready');

        const { count: failedChunks } = await supabase
          .from(pipeline.chunksTable)
          .select('id', { count: 'exact', head: true })
          .eq('document_id', doc.id)
          .eq('embedding_status', 'failed');

        const { count: processingChunks } = await supabase
          .from(pipeline.chunksTable)
          .select('id', { count: 'exact', head: true })
          .eq('document_id', doc.id)
          .eq('embedding_status', 'processing');

        const { count: waitingEnrichmentChunks } = await supabase
          .from(pipeline.chunksTable)
          .select('id', { count: 'exact', head: true })
          .eq('document_id', doc.id)
          .eq('embedding_status', 'waiting_enrichment');

        console.log(`  üìÑ ${doc.file_name}`);
        console.log(`     ID: ${doc.id}`);
        console.log(`     Created: ${doc.created_at}`);
        console.log(`     Updated: ${doc.updated_at}`);
        console.log(`     Chunks: total=${totalChunks || 0}, pending=${pendingChunks || 0}, ready=${readyChunks || 0}, failed=${failedChunks || 0}, processing=${processingChunks || 0}, waiting_enrichment=${waitingEnrichmentChunks || 0}`);

        if ((totalChunks || 0) === 0) {
          console.log(`     ‚ö†Ô∏è PROBLEM: Document has NO chunks! Should be reset to 'ingested'`);
        } else if ((pendingChunks || 0) === 0 && (readyChunks || 0) < (totalChunks || 0)) {
          console.log(`     ‚ö†Ô∏è PROBLEM: No pending chunks but not all ready. Check failed/processing/waiting_enrichment`);
        }
      }
    }
  }

  // Check cron jobs
  console.log('\nüìÖ Checking cron job history (last invocations)...');
  const { data: cronJobs } = await supabase
    .from('cron.job')
    .select('jobname, schedule, active')
    .ilike('jobname', '%pipeline%');

  if (cronJobs) {
    console.log('Cron jobs found:', cronJobs);
  } else {
    console.log('‚ö†Ô∏è Could not query cron jobs (may need service role key)');
  }

  console.log('\n‚úÖ Diagnosis complete. Check results above.');
}

// Helper to force re-extraction with cache invalidation
export async function forceReExtraction(agentId: string) {
  // Step 1: Restore all removed chunks FIRST (fresh start)
  await supabase.from('agent_knowledge')
    .update({ 
      is_active: true,
      removal_reason: null,
      removed_at: null
    })
    .eq('agent_id', agentId)
    .eq('is_active', false);
  
  // Step 2: Invalidate cache
  await supabase.from('agent_task_requirements')
    .update({ 
      extracted_at: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString(),
      system_prompt_hash: 'force-reextract'
    })
    .eq('agent_id', agentId);
  
  // Step 3: Re-extract requirements
  await supabase.functions.invoke('extract-task-requirements', {
    body: { agentId }
  });
  
  // Step 4: Re-analyze alignment with forceReanalysis flag
  return supabase.functions.invoke('analyze-knowledge-alignment', {
    body: { 
      agentId,
      forceReanalysis: true
    }
  });
}